{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb0caf9",
   "metadata": {},
   "source": [
    "# Delete CentralApnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fac2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44e8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_plus_normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecf10f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Normal              912\n",
       "ObstructiveApnea    649\n",
       "Hypopnea            398\n",
       "MixedApnea           72\n",
       "CentralApnea         38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b3c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "Normal          912\n",
      "Hypopnea        398\n",
      "MixedApnea       72\n",
      "CentralApnea     38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_plus_normal.csv\")\n",
    "\n",
    "# Remove rows where 'type' is 'ObstructiveApnea'\n",
    "df_filtered = df[df['type'] != 'ObstructiveApnea']\n",
    "\n",
    "# Save the new CSV\n",
    "df_filtered.to_csv(r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_without_obstructive.csv\", index=False)\n",
    "\n",
    "# Check result\n",
    "print(df_filtered['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6563f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "Normal    912\n",
      "Apnea     508\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV (ใช้ไฟล์ที่ตัด ObstructiveApnea ออกแล้ว)\n",
    "df = pd.read_csv(r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_without_obstructive.csv\")\n",
    "\n",
    "# รวมทุก class ที่ไม่ใช่ Normal ให้เป็น \"Apnea\"\n",
    "df['type'] = df['type'].apply(lambda x: 'Normal' if x == 'Normal' else 'Apnea')\n",
    "\n",
    "# Save เป็นไฟล์ใหม่\n",
    "df.to_csv(r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_binary_v2.csv\", index=False)\n",
    "\n",
    "# ตรวจสอบจำนวน class\n",
    "print(df['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d54a1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18ba9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 1: Import libraries =====\n",
    "import os, json, time, random, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import torchaudio\n",
    "    HAVE_TA = True\n",
    "except Exception:\n",
    "    HAVE_TA = False\n",
    "    print(\"[WARN] torchaudio not found, augmentation disabled.\")\n",
    "\n",
    "import pyedflib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    log_loss, average_precision_score\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor, Wav2Vec2ForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfbf3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060\n",
      "CUDA Version: 11.8\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: Device & seed =====\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6168cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: Load CSV and convert to binary classes =====\n",
    "df = pd.read_csv(r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_binary_v2.csv\")\n",
    "EDF_ROOT = r\"C:\\V89\\data2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "728937f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id\n",
       "995     374\n",
       "999     286\n",
       "1008    222\n",
       "1006    217\n",
       "1000    205\n",
       "1089    116\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['patient_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0edf2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b65bdcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "Normal    912\n",
      "Apnea     508\n",
      "Name: count, dtype: int64\n",
      "Label mapping: {'Apnea': np.int64(0), 'Normal': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# สมมติ df ตอนนี้มี column 'type' = ['Normal', 'Apnea', ...]\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['type'])\n",
    "\n",
    "print(df['type'].value_counts())\n",
    "print(\"Label mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "273c5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnoreApneaDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, edf_root, target_sr=16000):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.edf_root = Path(edf_root)\n",
    "        self.target_sr = target_sr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # สร้างชื่อไฟล์ EDF จาก patient_id และ segment_index\n",
    "        edf_filename = f\"{row['patient_id']:08d}-100507[{row['segment_index']+1:03d}].edf\"\n",
    "        edf_path = self.edf_root / edf_filename\n",
    "\n",
    "        label = row['label']\n",
    "\n",
    "        with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "            signal_labels = f.getSignalLabels()\n",
    "\n",
    "            # ดึง Mic และ Snore channels ถ้ามี\n",
    "            channels_to_load = []\n",
    "            for ch_name in [\"Mic\", \"Snore\"]:\n",
    "                if ch_name in signal_labels:\n",
    "                    ch_data = f.readSignal(signal_labels.index(ch_name)).astype(np.float32)\n",
    "                    channels_to_load.append(ch_data)\n",
    "\n",
    "            if not channels_to_load:\n",
    "                raise ValueError(f\"No 'Mic' or 'Snore' channel found in {edf_path}\")\n",
    "\n",
    "            # ทำให้ทุก channel ยาวเท่ากัน (ตัดให้สั้นเท่าตัวที่สั้นที่สุด)\n",
    "            min_len = min(len(ch) for ch in channels_to_load)\n",
    "            channels_to_load = [ch[:min_len] for ch in channels_to_load]\n",
    "\n",
    "            # รวมเป็น mono\n",
    "            waveform = np.mean(np.stack(channels_to_load, axis=0), axis=0)\n",
    "\n",
    "            # Resample ถ้าจำเป็น\n",
    "            orig_freq = f.getSampleFrequency(\n",
    "                signal_labels.index(\"Mic\" if \"Mic\" in signal_labels else \"Snore\")\n",
    "            )\n",
    "\n",
    "        waveform = torch.tensor(waveform, dtype=torch.float32)\n",
    "\n",
    "        if HAVE_TA and orig_freq != self.target_sr:\n",
    "            waveform = torchaudio.transforms.Resample(\n",
    "                orig_freq=orig_freq,\n",
    "                new_freq=self.target_sr\n",
    "            )(waveform)\n",
    "\n",
    "        # จำกัดความยาวสูงสุด 5 วินาที และ pad/truncate ให้เท่ากัน\n",
    "        MAX_INPUT_LENGTH = 16000 * 5  # 5 วินาที\n",
    "        inputs = self.processor(\n",
    "            waveform.numpy(),\n",
    "            sampling_rate=self.target_sr,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=MAX_INPUT_LENGTH,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        input_values = inputs.input_values.squeeze(0)\n",
    "        attention_mask = (\n",
    "            inputs.attention_mask.squeeze(0)\n",
    "            if \"attention_mask\" in inputs\n",
    "            else torch.ones_like(input_values)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77f23558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\V89\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:381: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 5: Prepare processor & dataloaders =====\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "train_df = df.sample(frac=0.8, random_state=SEED)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "train_dataset = SnoreApneaDataset(train_df, processor, EDF_ROOT)\n",
    "val_dataset = SnoreApneaDataset(val_df, processor, EDF_ROOT)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e68964ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'projector.weight', 'classifier.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'classifier.bias', 'projector.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 6: Model initialization =====\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\",\n",
    "    num_labels=2  # Only 2 classes now\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "total_steps = len(train_loader) * 5  # 5 epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38831e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60ad28144ae4c73a2b2fdc0b38f4560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\V89\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.6584 - Train Acc: 0.6294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3f040a1a364f86a1de9fd57685f066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Cell 7: Training loop with accuracy =====\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_values, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = train_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {epoch_loss:.4f} - Train Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293112df",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3686c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARY CLASSIFICATION REPORT:\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Apnea       0.00      0.00      0.00        91\n",
      "      Normal       0.68      1.00      0.81       193\n",
      "\n",
      "    accuracy                           0.68       284\n",
      "   macro avg       0.34      0.50      0.40       284\n",
      "weighted avg       0.46      0.68      0.55       284\n",
      "\n",
      "\n",
      "BINARY METRICS:\n",
      "ROC-AUC Score: 0.6130\n",
      "PR-AUC Score: 0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\V89\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\V89\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\V89\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAHHCAYAAACPy0PBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQxdJREFUeJzt3QmcjfX+wPHvczAztrEvo+xZs4WS6lqu7VIkpFBUorq2iORGtkIpKUndEiWiBZVWW1QolKQyWSambGWbhr8xOP/X91fn3DljcI5zzjzPmfN539dzZ87zPPOc3xnTnO98v9/f77HcbrdbAAAAbOSy88kBAAAUAQkAALAdAQkAALAdAQkAALAdAQkAALAdAQkAALAdAQkAALAdAQkAALAdAQkAALAdAQkQgbZt2yatW7eWQoUKiWVZsnjx4pBe/5dffjHXnT17dkivG8maNWtmNgDhQUACXKQdO3bIPffcI5UqVZK4uDiJj4+Xa6+9Vp555hn5v//7v7A+d69eveT777+Xxx57TObMmSMNGzaUnOKOO+4wwZB+P7P6Pmowpsd1e/LJJwO+/p49e2TMmDGyadOmEI0YQCjkDslVgCjzwQcfyM033yyxsbHSs2dPqVWrlpw8eVK++OILGTZsmPzwww/y3//+NyzPrW/Sa9eulYcfflj69+8flucoX768eZ48efKIHXLnzi3Hjx+X999/X7p27epzbO7cuSYAPHHixEVdWwOSsWPHSoUKFaRevXp+f92nn356Uc8HwD8EJECAkpKS5NZbbzVv2itWrJCEhATvsX79+sn27dtNwBIuv//+u/lYuHDhsD2HZh/0Td8uGuhptumNN944KyCZN2+eXH/99fLOO+9ky1g0MMqXL5/ExMRky/MB0YqSDRCgJ554QlJTU2XmzJk+wYjHZZddJoMGDfI+PnXqlIwfP14qV65s3mj1L/P//Oc/kpaW5vN1uv+GG24wWZarrrrKBARaDnrttde852ipQQMhpZkYDRz06zylDs/nGenX6HkZLV26VK677joT1BQoUECqVatmxnShHhINwP7xj39I/vz5zdfeeOON8tNPP2X5fBqY6Zj0PO11ufPOO82bu7+6d+8uH330kRw5csS7b/369aZko8cyO3TokAwdOlRq165tXpOWfNq2bSvfffed95zPPvtMrrzySvO5jsdT+vG8Tu0R0WzXxo0bpUmTJiYQ8XxfMveQaNlM/40yv/42bdpIkSJFTCYGgP8ISIAAaRlBA4VrrrnGr/PvvvtueeSRR6R+/fry9NNPS9OmTWXixIkmy5KZvol36dJFWrVqJU899ZR5Y9M3dS0BqU6dOplrqG7dupn+kalTpwY0fr2WBj4aEI0bN848T4cOHeTLL78879ctW7bMvNkeOHDABB1DhgyRNWvWmEyGBjCZaWbjzz//NK9VP9c3fS2V+EtfqwYLCxcu9MmOVK9e3XwvM9u5c6dp7tXXNmXKFBOwaZ+Nfr89wUGNGjXMa1Z9+/Y13z/dNPjwOHjwoAlktJyj39vmzZtnOT7tFSpRooQJTE6fPm32vfjii6a0M23aNClTpozfrxWAiLgB+O3o0aNu/c/mxhtv9Ov8TZs2mfPvvvtun/1Dhw41+1esWOHdV758ebNv9erV3n0HDhxwx8bGuh944AHvvqSkJHPe5MmTfa7Zq1cvc43MRo8ebc73ePrpp83j33///Zzj9jzHrFmzvPvq1avnLlmypPvgwYPefd99953b5XK5e/bsedbz3XXXXT7XvOmmm9zFihU753NmfB358+c3n3fp0sXdokUL8/np06fdpUuXdo8dOzbL78GJEyfMOZlfh37/xo0b5923fv36s16bR9OmTc2xF154IctjumX0ySefmPMfffRR986dO90FChRwd+zY8YKvEcDZyJAAAUhJSTEfCxYs6Nf5H374ofmo2YSMHnjgAfMxc69JzZo1TUnEQ/8C13KK/vUfKp7ek3fffVfOnDnj19fs3bvXzErRbE3RokW9++vUqWOyOZ7XmdG9997r81hfl2YfPN9Df2hpRsss+/btM+Ui/ZhVuUZpOczl+utXmmYs9Lk85ahvvvnG7+fU62g5xx869VpnWmnWRTM6WsLRLAmAwBGQAAHQvgSlpQh/7Nq1y7xJal9JRqVLlzaBgR7PqFy5cmddQ8s2hw8fllC55ZZbTJlFS0mlSpUypaM333zzvMGJZ5z65p6ZlkH++OMPOXbs2Hlfi74OFchradeunQn+FixYYGbXaP9H5u+lh45fy1lVqlQxQUXx4sVNQLd582Y5evSo3895ySWXBNTAqlOPNUjTgO3ZZ5+VkiVL+v21AP6HgAQIMCDR3oAtW7YE9HWZm0rPJVeuXFnud7vdF/0cnv4Gj7x588rq1atNT8jtt99u3rA1SNFMR+ZzgxHMa/HQwEIzD6+++qosWrTonNkRNWHCBJOJ0n6Q119/XT755BPTvHv55Zf7nQnyfH8C8e2335q+GqU9KwAuDgEJECBtmtRF0XQtkAvRGTH6ZqgzQzLav3+/mT3imTETCpqByDgjxSNzFkZp1qZFixam+fPHH380C6xpSWTlypXnfB0qMTHxrGNbt2412QideRMOGoTom75mpbJqBPZ4++23TQOqzn7S87Sc0rJly7O+J/4Gh/7QrJCWd7TUpk2yOgNLZwIBCBwBCRCgBx980Lz5aslDA4vMNFjRGRiekoPKPBNGAwGl62mEik4r1tKEZjwy9n5oZiHz9NjMPAuEZZ6K7KHTm/UczVRkfIPXTJHOKvG8znDQIEOnTT/33HOm1HW+jEzm7Mtbb70lv/32m88+T+CUVfAWqOHDh8vu3bvN90X/TXXatc66Odf3EcC5sTAacBFv/Dr9VMsc2j+RcaVWnQarb4La/Knq1q1r3qB01VZ9A9QpqF9//bV5A+vYseM5p5ReDM0K6BvkTTfdJAMHDjRrfsyYMUOqVq3q09SpDZhastFgSDMfWm54/vnn5dJLLzVrk5zL5MmTzXTYxo0bS+/evc1Krjq9VdcY0WnA4aLZnJEjR/qVudLXphkLnZKt5RPtO9Ep2pn//bR/54UXXjD9KRqgNGrUSCpWrBjQuDSjpN+30aNHe6chz5o1y6xVMmrUKJMtARCALGbeAPDDzz//7O7Tp4+7QoUK7piYGHfBggXd1157rXvatGlmCqpHenq6mapasWJFd548edxly5Z1jxgxwuccpVN2r7/++gtONz3XtF/16aefumvVqmXGU61aNffrr79+1rTf5cuXm2nLZcqUMefpx27dupnXk/k5Mk+NXbZsmXmNefPmdcfHx7vbt2/v/vHHH33O8Txf5mnFei3dr9f2d9rvuZxr2q9Oj05ISDDj03GuXbs2y+m67777rrtmzZru3Llz+7xOPe/yyy/P8jkzXiclJcX8e9WvX9/8+2Y0ePBgMxVanxuA/yz9v0ACGAAAgFCjhwQAANiOgAQAANiOgAQAANiOgAQAANiOgAQAANiOgAQAANiOhdGygS4dvmfPHrMIUyiXrQYAhJ+ujqG3LtD7WHnuKB0OJ06cMAsshoLeIFLvPh1JCEiygQYjZcuWtXsYAIAgJCcnmxWNwxWM5C1YTOTU8ZBcT2+zkJSUFFFBCQFJNtDMiNqelCwF/759PZDTTFzuewNBIKdIO54qM+5o5v1dHg4nNTNy6rjE1uwlkismuIudPin7fnzVXJOABD48ZRoNRvT29UBOFJuvgN1DAMIqW0ruuePECjIgcVuR2R5KQAIAgFNYJvIJ/hoRiIAEAACnsFx/bcFeIwJF5qgBAECOQoYEAACnsKwQlGwis2ZDQAIAgFNYlGwAAABsQ4YEAACnsCjZAAAA27lCUHKJzOJHZI4aAADkKGRIAABwCouSDQAAsJvFLBsAAADbkCEBAMApLEo2AADAblb0lmwISAAAcAorejMkkRlGAQCAHIUMCQAATmFRsgEAAI4o2biCv0YEiswwCgAA5ChkSAAAcAqX9dcW7DUiEAEJAABOYUVvD0lkjhoAAOQoZEgAAHAKK3rXISEgAQDAKSxKNgAAALYhQwIAgFNYlGwAAIDdLEo2AADAKRkSK8gtAKtXr5b27dtLmTJlxLIsWbx4caYhWVlukydP9p5ToUKFs45PmjQpoHEQkAAAEMWOHTsmdevWlenTp2d5fO/evT7bK6+8YgKOzp07+5w3btw4n/MGDBgQ0Dgo2QAAEMUlm7Zt25rtXEqXLu3z+N1335XmzZtLpUqVfPYXLFjwrHMDQYYEAIAoLtkEYv/+/fLBBx9I7969zzqmJZpixYrJFVdcYco5p06dCujaZEgAAMiBUlJSfB7HxsaaLRivvvqqyYR06tTJZ//AgQOlfv36UrRoUVmzZo2MGDHClG2mTJni97UJSAAAcAxXCGbJ/PX1ZcuW9dk7evRoGTNmTFBX1v6RHj16SFxcnM/+IUOGeD+vU6eOxMTEyD333CMTJ070OwgiIAEAIAeuQ5KcnCzx8fHe3cFmRz7//HNJTEyUBQsWXPDcRo0amZLNL7/8ItWqVfPr+gQkAADkQPHx8T4BSbBmzpwpDRo0MDNyLmTTpk3icrmkZMmSfl+fgAQAAEdlSFzBXyMAqampsn37du/jpKQkE1BoP0i5cuW8/ShvvfWWPPXUU2d9/dq1a+Wrr74yM2+0v0QfDx48WG677TYpUqSI3+MgIAEAIIqn/W7YsMEEE5n7QXr16iWzZ882n8+fP1/cbrd069btrK/XUpAe1/6UtLQ0qVixoglIMvaV+IOABACAKNasWTMTbJxP3759zZYVnV2zbt26oMdBQAIAgFNY3FwPAADYzYrem+sRkAAA4BRW9GZIIjOMAgAAOQoZEgAAnMKiZAMAAOxmUbIBAACwDRkSAAAcwrIsswV5EYlEBCQAADiEFcUBCSUbAABgOzIkAAA4hfX3Fuw1IhABCQAADmFRsgEAALAPGRIAABzCiuIMCQEJAAAOYRGQAAAAu1lRHJDQQwIAAGxHhgQAAKewmPYLAABsZlGyAQAAsA8ZEgAAHMKy/sqSBHcRiUgEJAAAOISl/wu65BKZEQklGwAAYDsyJAAAOIQVxU2tBCQAADiFFb3TfinZAAAA25EhAQDAKazgSzZuSjYAAMDuHhKLgAQAAATDiuKAhB4SAABgOzIkAAA4hRW9s2wISAAAcAiLkg0AAIB9yJAAAOAQVhRnSAhIAABwCCuKAxJKNgAAwHZkSAAAcAiLDAkAAHDMtF8ryC0Aq1evlvbt20uZMmVMMLN48WKf43fccYc3UPJs//rXv3zOOXTokPTo0UPi4+OlcOHC0rt3b0lNTQ1oHAQkAABEsWPHjkndunVl+vTp5zxHA5C9e/d6tzfeeMPnuAYjP/zwgyxdulSWLFligpy+ffsGNA5KNgAARHHJpm3btmY7n9jYWCldunSWx3766Sf5+OOPZf369dKwYUOzb9q0adKuXTt58sknTebFH2RIAABwCCtTaeRiN5WSkuKzpaWlXfS4PvvsMylZsqRUq1ZN7rvvPjl48KD32Nq1a02ZxhOMqJYtW4rL5ZKvvvrK7+cgIAEAIAcGJGXLlpVChQp5t4kTJ17UmLRc89prr8ny5cvl8ccfl1WrVpmMyunTp83xffv2mWAlo9y5c0vRokXNMX9RsgEAIAdKTk42TaYZyy4X49Zbb/V+Xrt2balTp45UrlzZZE1atGghoUKGBACAHDjLJj4+3me72IAks0qVKknx4sVl+/bt5rH2lhw4cMDnnFOnTpmZN+fqO8kKAQkAADmwZBMuv/76q+khSUhIMI8bN24sR44ckY0bN3rPWbFihZw5c0YaNWrk93Up2QAAEMVSU1O92Q6VlJQkmzZtMj0guo0dO1Y6d+5ssh07duyQBx98UC677DJp06aNOb9GjRqmz6RPnz7ywgsvSHp6uvTv39+UevydYaMISJDjvPTmKpn2+nI5cDBFalW5RB4fdrM0uLyC3cMCAnYy7aSsXbZOdvy4U44fOy4lE0pIk+ubSOlLS5nj23/YLt9/vUUO7PldTvzfCene71YpkVDC7mEjwqb9btiwQZo3b+59PGTIEPOxV69eMmPGDNm8ebO8+uqrJguiAUbr1q1l/PjxPiWguXPnmiBEe0p0do0GMM8++2xA43B0QKJTia677joTeX3wwQd2DwcRYOGnG2Xk1EUy5aFbpEGtCvLCGyul84Dpsv7tR6RE0YJ2Dw8IyLJFy+XggUPSpksryR+fX7ZuSpRFsxbL7YN6SIH4ApJ+8pSUKV9GqtSuIssXr7B7uAgBS0IQkAS4VGuzZs3E7Xaf8/gnn3xywWtoJmXevHkSDEf3kMycOVMGDBhgVnzbs2eP3cNBBHh+3grp2fEa6dGhsVSvlCBTRtwq+eJi5PX31to9NCAgp9JPyfYfd8h1ba6RSypeIoWLFZarWzSSwsUKyeavvjfn1LiiujT651VSrnJZu4cLBM3l5JrWggULzAIs119/vcyePdt7TKcaaQSpWROdfhQXFydXX321bNmyxXuOnq8LtWhkp/WtAgUKeJe+zejll182x/Ua1atXl+eff97n+PDhw6Vq1aqSL18+01k8atQoUx+D85xMPyWbtiZLs6uqefdp6rDpVdVk/fdJto4NCJQ2BLrPuCVXbt9Etj7es8v39xhyDisCmlqjLiB58803TYCgq8Lddttt8sorr5yVUho2bJg89dRTZrnaEiVKmJsDZQwWjh8/bpatnTNnjsmy7N69W4YOHepT83rkkUfkscceM0vfTpgwwQQcWivzKFiwoAlufvzxR3nmmWfkpZdekqeffjqbvgsIxMEjqXL69JmzSjMlisabfhIgksTExkhC2dLy9cr1kpqSagKUrZu2yr7kfXIs9Zjdw0MOurmeU+R2crlGAxGlmY2jR4+a1eG01uUxevRoadWqlflcg4hLL71UFi1aJF27djX7NDjRjl9dwEVpw824ceN8vl4Dmk6dOpnHFStWNIHHiy++aJp51MiRI73nV6hQwQQ08+fPN13G56LL82ZcoleX7AWAQLXu0lqWLVomM5+YJZbLMk2tVetUlQN7fNd8AHICRwYkiYmJ8vXXX5vgwrME7S233GKClIwBic59zthQo9kUzXR4aJnFE4wonTPtWbxF726o05f0Fsk6VSnjYi66xK6Hlo20U1jP1TKSHs+48l1WdHlenSaF7FWscAHJlcslvx/602f/74dSpGSx8/+bAU6k/SJd7u4s6SfTzYyb/AXzy4fzP5JCRfh5zqksG2bZOIUjAxINPPSNP+P8ZS3X6BSj5557zu/r5MmT56x/JE/ZR4MLpSWYzAu35MqVyzvLR2+prMGFzrfWQEWzI5pVOZ8RI0Z4p015MiR6TwGEV0ye3FKvellZtT5Rrm9W1+zTNPfq9T/L3Tc3sXt4wEXLE5PHbDq1d9f23XJdm2vtHhLCxCIgcQ4NRPQmPvqmr3OdM+rYsaO88cYbprdErVu3TsqVK2c+P3z4sPz888+mQdUfpUqVMgHPzp07TdCRlTVr1kj58uXl4Ycf9u7btWvXBa+tgVOoluhFYP7d/Z/y77Fz5Ioa5aT+5RVkxhsr5dj/pUmP9lfbPTQgYLu27RL9G6pI8cJy5NBR+eLjL6Vo8SJSs/5fv+dOHD8hfx79U1JT/uopOfzHYfMxX4F8JpuCyGNZf23BXiMSOS4gWbJkiQkutJSSsXSidKEVzZ5MnjzZPNZ+kGLFipngQoMGXVtfgxZ/aeZj4MCB5nm0T0X7PnSBGH1+zXBUqVLFNMJqVuTKK680s3o8ZSQ4U6fWDeSPI6ky4cUP5MDBP6V21Uvk7Wf7UbJBREo7cVLWfLrGNLXG5o2Tyy6vLNe0auzN4u7cmiRLFy7znv/Rgr/Wi2jU/CozRRiIJI4LSDTgaNmy5VnBiCcgeeKJJ8yqcWrSpEkyaNAg2bZtm9SrV0/ef/99iYmJ8fu57r77btNnogGOztjJnz+/uZPh/fffb4536NBBBg8ebJphNVjR6cc6C2fMmDEhfMUItb5dm5oNiHRVa1cx27lopsSTLUFOypBYQV8jElnu8y3P5lC6Dokuc6uZDF1rxOm0h0QDrP0Hj16wIRaIVGM+SbR7CEBYpB1PlaldG5rZnuH6HZ7y9/tEpYFvS67Y4Mptp9OOyc5nu4R1vFG1DgkAAIgejivZAAAQrSxm2USWC90ICACASGRF8SwbSjYAAMB2EZkhAQAgJ3K5LLMFwx3k19uFgAQAAIewKNkAAADYhwwJAAAOYTHLBgAA2M2K4pINAQkAAA5hRXGGhB4SAABgOzIkAAA4hBXFGRICEgAAHMKK4h4SSjYAAMB2ZEgAAHAIS0JQspHITJEQkAAA4BAWJRsAAAD7kCEBAMAhLGbZAAAAu1mUbAAAAOxDhgQAAIewKNkAAAC7WVFcsiEgAQDAIawozpDQQwIAAGxHhgQAAKewQlByicwECQEJAABOYVGyAQAAsA8BCQAADptlYwW5BWL16tXSvn17KVOmjMmuLF682HssPT1dhg8fLrVr15b8+fObc3r27Cl79uzxuUaFChW82R3PNmnSpIDGQUACAIBDWJne1C92C8SxY8ekbt26Mn369LOOHT9+XL755hsZNWqU+bhw4UJJTEyUDh06nHXuuHHjZO/evd5twIABAY2DHhIAAKJY27ZtzZaVQoUKydKlS332Pffcc3LVVVfJ7t27pVy5ct79BQsWlNKlS1/0OMiQAACQA0s2KSkpPltaWlpIxnj06FGThSlcuLDPfi3RFCtWTK644gqZPHmynDp1KqDrkiEBACAHzrIpW7asz/7Ro0fLmDFjgrr2iRMnTE9Jt27dJD4+3rt/4MCBUr9+fSlatKisWbNGRowYYco2U6ZM8fvaBCQAAORAycnJPkFDbGxsUNfTBteuXbuK2+2WGTNm+BwbMmSI9/M6depITEyM3HPPPTJx4kS/n5eABACAHJghiY+P9wlIQhGM7Nq1S1asWHHB6zZq1MiUbH755RepVq2aX89BQAIAgENYDry5nicY2bZtm6xcudL0iVzIpk2bxOVyScmSJf1+HgISAACieKXW1NRU2b59u/dxUlKSCSi0HyQhIUG6dOlipvwuWbJETp8+Lfv27TPn6XEtzaxdu1a++uorad68uZlpo48HDx4st912mxQpUsTvcRCQAAAQxTZs2GCCicz9IL169TJNsO+99555XK9ePZ+v02xJs2bNTI/I/Pnzzbk6k6dixYomIMnYV+IPAhIAAKK4ZNOsWTPTqHou5zumdHbNunXrJFgEJAAAOITFzfUAAADsQ4YEAACHsEIwSyYy8yMEJAAAOIbLsswW7DUiESUbAABgOzIkAAA4hOXAhdGyCwEJAAAOYUXxLBsCEgAAHMJl/bUFe41IRA8JAACwHRkSAACcwgpBySVCMyQEJAAAOIQVxU2tlGwAAIDtyJAAAOAQ1t//C/YakYiABAAAh3AxywYAAMA+ZEgAAHAIi4XRzu+9997z+4IdOnQIZjwAAEQtK4pn2fgVkHTs2NHvqOz06dPBjgkAAEQZvwKSM2fOhH8kAABEOZdlmS3Ya0RdD8mJEyckLi4udKMBACCKWVFcsgl4lo2WZMaPHy+XXHKJFChQQHbu3Gn2jxo1SmbOnBmOMQIAEFVNrVaQW1QEJI899pjMnj1bnnjiCYmJifHur1Wrlrz88suhHh8AAIgCAQckr732mvz3v/+VHj16SK5cubz769atK1u3bg31+AAAiLqSjRXkFhU9JL/99ptcdtllWTa+pqenh2pcAABEHVcUN7UGnCGpWbOmfP7552ftf/vtt+WKK64I1bgAAEAUCThD8sgjj0ivXr1MpkSzIgsXLpTExERTylmyZEl4RgkAQBSw/t6CvUZUZEhuvPFGef/992XZsmWSP39+E6D89NNPZl+rVq3CM0oAAKKAFcWzbC5qHZJ//OMfsnTp0tCPBgAARKWLXhhtw4YNJjPi6Stp0KBBKMcFAEDUcVl/bcFeIyoCkl9//VW6desmX375pRQuXNjsO3LkiFxzzTUyf/58ufTSS8MxTgAAcjwriu/2G3APyd13322m92p25NChQ2bTz7XBVY8BAACEPUOyatUqWbNmjVSrVs27Tz+fNm2a6S0BAAAXz4rMBEf2ByRly5bNcgE0vcdNmTJlQjUuAACijkXJxn+TJ0+WAQMGmKZWD/180KBB8uSTT4Z6fAAARF1TqyvILcdmSIoUKeITcR07dkwaNWokuXP/9eWnTp0yn991113SsWPH8I0WAADkSH4FJFOnTg3/SAAAiHJWFJds/ApIdKl4AAAQXhZLx1+cEydOSEpKis8GAAAix+rVq6V9+/ZmYopmVxYvXuxz3O12m9vEJCQkSN68eaVly5aybds2n3N0CZAePXpIfHy8WaOsd+/ekpqaGt6ARPtH+vfvLyVLljT3stH+kowbAAC4OC7LCskW6Pt63bp1Zfr06Vkef+KJJ+TZZ5+VF154Qb766ivz3t+mTRuTlPDQYOSHH34wt5XRG+1qkNO3b9/wTvt98MEHZeXKlTJjxgy5/fbbzQvQO/+++OKLMmnSpEAvBwAA/qaxRLAtIIF+fdu2bc2WFc2OaB/pyJEjzc111WuvvSalSpUymZRbb73VLI768ccfy/r166Vhw4bmHF2brF27dmb2rb9LggScIdG7+j7//PPSuXNnM7NGF0PTgU6YMEHmzp0b6OUAAEAYZG6pSEtLC/gaSUlJsm/fPlOm8ShUqJCZabt27VrzWD9qmcYTjCg93+VymYyKvwIOSLROVKlSJfO51or0sbruuutMigYAAAQ3y8YKcvMsZKrBg2ebOHFiwOPRYERpRiQjfew5ph+1jSMjTVgULVrUe05YSjYajGjEVK5cOalevbq8+eabctVVV5nMiedmewAAwN6STXJyskkceMTGxoqTBZwhufPOO+W7774znz/00EOmhyQuLk4GDx4sw4YNC8cYAQBAgDQYybhdTEBSunRp83H//v0++/Wx55h+PHDggM9xXTBVKyiec8KSIdHAI2ONaOvWrbJx40a57LLLpE6dOoFeDgAA/O1iZslkFuzXZ1SxYkUTVCxfvlzq1atn9mk/ivaG3HfffeZx48aN5ciRIyYWaNCggdm3YsUKOXPmjOk1CVtAkln58uXNBgAAIm+WTWpqqmzfvt37WNsyNm3aZHpAtD3j/vvvl0cffVSqVKliApRRo0aZmTOeW8XUqFFD/vWvf0mfPn3M1GC9Aa8uD6IzcAK56a5fAYnOP/bXwIED/T4XAAD8jx1Lx+sNcps3b+59PGTIEO8q7bNnzzbLfehaJbquiGZCdBKLTvPVdg0PnWWrQUiLFi3M7BqdiRtI7GDG7dZJxhegEZFfF7Ms2blzZ0ADiAaa3tIO5/0Hj/o0GAE5yZhPEu0eAhAWacdTZWrXhnL0aPh+h6f8/T5x9+tfS0y+AkFd6+TxVHn5tqvCOt5w8CtDoukbADifZ0ZOs3sIQFi4T5/M1pkmrhBcIxIF3UMCAABCw4riu/1GaiAFAAByEDIkAAA4hGXptN3grxGJCEgAAHAIVwgCkmC/3i6UbAAAQGQGJJ9//rncdtttZnW23377zeybM2eOfPHFF6EeHwAAUcMK4c31cnxA8s4770ibNm0kb9688u2333pvZ6zznSdMmBCOMQIAEFUlG1eQW1QEJLp8rC4N+9JLL0mePHm8+6+99lr55ptvQj0+AAAQBQJuak1MTJQmTZqctV9XmNMlZQEAQOTcyyZiMyR617+MN+Hx0P6RSpUqhWpcAABE7d1+XUFuURGQ6N38Bg0aZG49rI0ze/bsMTfVGTp0qPdWxAAA4OKXjncFuUVFyeahhx6SM2fOmDv6HT9+3JRvYmNjTUAyYMCA8IwSAADkaAEHJJoVefjhh2XYsGGmdJOamio1a9aUAgWCuzshAADRzoriHpKLXqk1JibGBCIAACA0XBJ8D4heIyoCkubNm5930ZUVK1YEOyYAABBlAg5I6tWr5/M4PT1dNm3aJFu2bJFevXqFcmwAAEQVi5KN/55++uks948ZM8b0kwAAgIvj4uZ6wdN727zyyiuhuhwAAIgiF93UmtnatWslLi4uVJcDACDqWCZDElyKI2pKNp06dfJ57Ha7Ze/evbJhwwYZNWpUKMcGAEBUsegh8Z/esyYjl8sl1apVk3Hjxknr1q1DOTYAABAlAgpITp8+LXfeeafUrl1bihQpEr5RAQAQhVw0tfonV65cJgvCXX0BAAg9K0T/i4pZNrVq1ZKdO3eGZzQAAEQxlxWaLSoCkkcffdTcSG/JkiWmmTUlJcVnAwAACFsPiTatPvDAA9KuXTvzuEOHDj5LyOtsG32sfSYAACBwrijuIfE7IBk7dqzce++9snLlyvCOCACAKGVZ1nnvF+fvNXJ0QKIZENW0adNwjgcAAESh3NEQdQEAEAlclGz8U7Vq1QsGJYcOHQp2TAAARCWLlVr97yPJvFIrAABAtgYkt956q5QsWTLoJwUAAGdzWVbQN9cL9usdH5DQPwIAQHi5oriHxBXoLBsAAADbMiRnzpwJ+ZMDAIAMQtDUGqG3sgmshwQAAISPSyyzBXuNqLiXDQAACO+0XyvIzV8VKlTwrg6bcevXr5853qxZs7OO6art4UCGBACAKLV+/Xqfe9Bt2bJFWrVqJTfffLN3X58+fcz97Dzy5csXlrEQkAAAEKWzbEqUKOHzeNKkSVK5cmWf28RoAFK6dGkJN0o2AAA4bB0SV5CbSklJ8dnS0tLO+9wnT56U119/Xe666y6fpT7mzp0rxYsXl1q1asmIESPk+PHjYXntZEgAAMiBypYt6/N49OjRMmbMmHOev3jxYjly5Ijccccd3n3du3eX8uXLS5kyZWTz5s0yfPhwSUxMlIULF4Z8vAQkAADkwHvZJCcnS3x8vHd/bGzseb9u5syZ0rZtWxN8ePTt29f7ee3atSUhIUFatGghO3bsMKWdUCIgAQDASdN+rdBM+9VgJGNAcj67du2SZcuWXTDz0ahRI/Nx+/btIQ9I6CEBACDKzZo1y9yr7vrrrz/veZs2bTIfNVMSamRIAADIgSWbQFZi14CkV69ekjv3/8ICLcvMmzdP2rVrJ8WKFTM9JIMHD5YmTZpInTp1JNQISAAAcAhXCEoXgX69lmp2795tZtdkFBMTY45NnTpVjh07ZppkO3fuLCNHjpRwICABACCKtW7dOssb6GoAsmrVqmwbBwEJAAAOYf29PHuw14hEBCQAADiEFYKb9UZmOEJAAgCAY7gyrLQazDUiEdN+AQCA7ciQAADgIJZEJwISAACieB0Sp6BkAwAAbEeGBAAAh7CY9gsAAKJxpVaniNRxAwCAHIQMCQAADmFRsgEAAHazonilVko2AADAdmRIAABwCIuSDQAAsJsrimfZEJAAAOAQVhRnSCI1kAIAADkIGRIAABzCiuJZNgQkAAA4hMXN9QAAAOxDhgQAAIdwiWW2YK8RiQhIAABwCIuSDQAAgH3IkAAA4BDW3/8L9hqRiIAEAACHsCjZAAAA2IcMCQAADmGFYJYNJRsAABAUK4pLNgQkAAA4hBXFAQk9JAAAwHZkSAAAcAiLab8AAMBuLuuvLdhrRCJKNgAAwHZkSAAAcAiLkg0AALCbxSwbAAAA+5AhAQDAIawQlFwiNEFChgQAAKfNsnEFuflrzJgxYlmWz1a9enXv8RMnTki/fv2kWLFiUqBAAencubPs378/PK89LFcFAAAR4fLLL5e9e/d6ty+++MJ7bPDgwfL+++/LW2+9JatWrZI9e/ZIp06dwjIOSjYB+uyzz6R58+Zy+PBhKVy4sN3DQRZeenOVTHt9uRw4mCK1qlwijw+7WRpcXsHuYQHndc0VlWXA7S2lbvVyklCikPQY+l/5cNVm7/ESRQvKmAE3SvNGNaRQwbyy5tvtMnzyW7Iz+XfvOU+PuFWaXlVNShcvJMf+L02+3pwkY6a9K9t2hecvWuSMWTa5c+eW0qVLn7X/6NGjMnPmTJk3b57885//NPtmzZolNWrUkHXr1snVV18tOSZDcscdd5j00KRJk3z2L1682OwHArXw040ycuoiGX53W/lsznATkHQeMF1+P/Sn3UMDzitf3ljZ8vNvMuyJBVkef31yX6lQprj0GPqiNL1tkvy695Asnj5A8sXFeM/ZtDVZ+o97XRp1fdT83Ovv0YXP9RNXpK6UFcWzbKwgN5WSkuKzpaWlZfmc27ZtkzJlykilSpWkR48esnv3brN/48aNkp6eLi1btvSeq+WccuXKydq1a3NeySYuLk4ef/xxk3EIlZMnT4bsWogsz89bIT07XiM9OjSW6pUSZMqIW80v7NffC/1/PEAoLVvzozz2whL54LP/ZUU8KpcrKVfVqSgPPD5fvv1xt2zfdUCGTFogcbF5pHObBt7zXl30paz5dock7z0kmxN/lcdmvC+Xli4q5RKKZfOrQXBNrRL0psqWLSuFChXybhMnTjzr+Ro1aiSzZ8+Wjz/+WGbMmCFJSUnyj3/8Q/7880/Zt2+fxMTEnFUNKFWqlDmW4wISjbw0VZTVN8rjnXfeMTWu2NhYqVChgjz11FM+x3Xf+PHjpWfPnhIfHy99+/Y132D9Ji5ZskSqVasm+fLlky5dusjx48fl1VdfNV9TpEgRGThwoJw+fdp7rTlz5kjDhg2lYMGCZlzdu3eXAwcOhPV7gNA4mX7K/IXY7Kpq3n0ul8uksNd/n2Tr2IBgxOb5q7p+Iu2Ud5/b7TY/81fXq5zl12gg3r391fLLb3/Ib/tD9wcfIkdycrIpu3i2ESNGnHVO27Zt5eabb5Y6depImzZt5MMPP5QjR47Im2++me3jtT0gyZUrl0yYMEGmTZsmv/7661nHNWXUtWtXufXWW+X77783HcGjRo0yAUdGTz75pNStW1e+/fZbc1xp8PHss8/K/PnzTfSn/R833XST+YbrpsHHiy++KG+//bb3Opqe0uDmu+++M6WjX375xZSWAqFpscypMoTfwSOpcvr0GVNrz6hE0XjTTwJEqp9/2WeyHo/062D6R/LkziWDeraUS0oVkVLFCvmc27vLPyR51VPy2+dTpOU1NeWmfs9J+qn//dEFZ3OJJS4ryO3vHIn+gZ5x0z/qL0T/kK9ataps377d/FGuFQcNUDLSWTZZ9ZwE/9odQIOEevXqyejRo886NmXKFGnRooUJMvSbpMFB//79ZfLkyT7nacPNAw88IJUrVzabJ7jQFNQVV1whTZo0MRkS7R7WJp2aNWvKDTfcYBpUV65c6b3OXXfdZSJGraVpw44GNB999JGkpqb6/Xo025MxTaZpMwC4WKdOn5HbH3xJLitfUn5ZMVn2fD5FrmtYVZZ++YO43Wd8zn3ro/Wmx+T6vk/Ljt2/y6yJd0lsDPMXorFkczH0vW7Hjh2SkJAgDRo0kDx58sjy5cu9xxMTE02PSePGjSVHBiRK+0i0lPLTTz/57NfH1157rc8+faxNOBlLLVpmyUzLNJ7gxFP30lKNzqXOuC9jSUYzMu3btzdNO1q2adq0qdnvafLxh6bFMqbJNG2G8CtWuIDkyuU6q4H190MpUrJYvG3jAkLhu63J0qTHJCnfbKhUb/uw3DzweSlSKL/88ttBn/NSjp0wM2+0l6TX8JelSoVSckOzuraNG842dOhQM51XqwFr1qwxCQKtXHTr1s38Qd27d28ZMmSI+cNd3x/vvPNOE4yEeoaNowISzWBo/SqrGpc/8ufPf9Y+jewy0o7zrPadOfPXXxjHjh0zY9DU1ty5c2X9+vWyaNGigBtlNS2WOVWG8IvJk1vqVS8rq9Ynevfpv+3q9T/LlbUr2jo2IFQ04NDyZKWyJeSKGuV8pgZn5lnoKoYMSeSwsjdFoq0SGnxor6W2R+gCaDqlt0SJEub4008/baoJuiCavk9rqWbhwoVheemO+inV6b9autFvjIfOd/7yyy99ztPHWr7RKC6Utm7dKgcPHjTj8JRZNmzYENLnQHj9u/s/5d9j55hf1PUvryAz3lhp1mPo0T700TwQSvnzxkjFsn+9CajyZYpJraqXyJGjx+XX/YflxhZXyB+HU+XX/YekZuUyMumBLvLBqs2y8qutf51/STHp1KqBrFj3kxw8nCplShWW+3u1lhMn0k1pB5HByuZ1SLTH8kIzYadPn262cHNUQFK7dm0zB1r7Njy0L+TKK680jaa33HKLmfv83HPPyfPPPx/y59cyjU5x0gbbe++9V7Zs2WKeF5GjU+sG8seRVJnw4gdy4OCfUrvqJfL2s/0o2cDx6tUoL0teHOR9PGFIZ/Nx3pJ10m/s61KqeLw8NriTadre/0eKzP/wK5n88sfe89PSTknjepXl3lubSeH4fKZ0qYuntbn7KRPIAE7nqIBEjRs3ThYs+N/CQPXr1zfTjx555BETHGijjZ4T6MwXf2iKSmfv/Oc//zFBkT63zt7p0KFDyJ8L4dO3a1OzAZHky2+2SZEr+5/z+H8XrDLbuez746h0vX9GmEaHbGP9b2GzYK4RiSy3TmZHWOm0X20O2n/wKP0kyLHO92YKRDL36ZOS9v1LZpJCuH6Hp/z9PrFi024pUDC450j9M0X+Wa9cWMcbDo5pagUAANHLcSUbAACilhWCkkuElmwISAAAiOK7/ToFAQkAAA5hhaCpNeimWJvQQwIAAGxHhgQAAIeworeFhIAEAADHsKI3IqFkAwAAbEeGBAAAh7CYZQMAAOxmMcsGAADAPmRIAABwCCt6e1oJSAAAcAwreiMSSjYAAMB2ZEgAAHAIi1k2AADAblYUz7IhIAEAwCGs6G0hoYcEAADYjwwJAABOYUVvioSABAAAh7CiuKmVkg0AALAdGRIAABzCYpYNAACwmxW9LSSUbAAAgP3IkAAA4BRW9KZICEgAAHAIi1k2AAAA9iFDAgCAQ1jMsgEAAHazoreFhIAEAADHsKI3IqGHBAAA2I4MCQAADmFF8SwbAhIAAJzCCkFTamTGI5RsAACA/QhIAABwWE+rFeTmr4kTJ8qVV14pBQsWlJIlS0rHjh0lMTHR55xmzZqJZVk+27333hvy105AAgBAlEYkq1atkn79+sm6detk6dKlkp6eLq1bt5Zjx475nNenTx/Zu3evd3viiSdC/tLpIQEAIEp9/PHHPo9nz55tMiUbN26UJk2aePfny5dPSpcuHdaxkCEBAMBhs2ysIP+nUlJSfLa0tLQLPv/Ro0fNx6JFi/rsnzt3rhQvXlxq1aolI0aMkOPHj4f8tZMhAQAgBy4dX7ZsWZ/9o0ePljFjxpzz686cOSP333+/XHvttSbw8OjevbuUL19eypQpI5s3b5bhw4ebPpOFCxdKKBGQAACQAyUnJ0t8fLz3cWxs7HnP116SLVu2yBdffOGzv2/fvt7Pa9euLQkJCdKiRQvZsWOHVK5cOWTjJSABACAHrhwfHx/vE5CcT//+/WXJkiWyevVqufTSS897bqNGjczH7du3E5AAAJAjWdl7Lxu32y0DBgyQRYsWyWeffSYVK1a84Nds2rTJfNRMSSgRkAAAEKVLx/fr10/mzZsn7777rlmLZN++fWZ/oUKFJG/evKYso8fbtWsnxYoVMz0kgwcPNjNw6tSpI6FEQAIAQJSaMWOGd/GzjGbNmiV33HGHxMTEyLJly2Tq1KlmbRJtlO3cubOMHDky5GMhIAEAwEkVGyv4awRSsjkfDUB08bTsQEACAEB0tpA4CgujAQAA25EhAQAgBy6MFmkISAAAcAwraos2lGwAAIDtyJAAAOAQFiUbAABgNytqCzaUbAAAgAOQIQEAwCEsSjYAACDa7mXjJAQkAAA4hRW9TST0kAAAANuRIQEAwCGs6E2QEJAAAOAUVhQ3tVKyAQAAtiNDAgCAQ1jMsgEAALazoreJhJINAACwHRkSAAAcworeBAkBCQAATmExywYAAMA+ZEgAAHAMKwSzZCIzRUJAAgCAQ1iUbAAAAOxDQAIAAGxHyQYAAIeworhkQ0ACAIBDWFG8dDwlGwAAYDsyJAAAOIRFyQYAANjNiuKl4ynZAAAA25EhAQDAKazoTZEQkAAA4BAWs2wAAADsQ4YEAACHsJhlAwAA7GZFbwsJJRsAABwXkVhBbgGaPn26VKhQQeLi4qRRo0by9ddfS3YjIAEAIIotWLBAhgwZIqNHj5ZvvvlG6tatK23atJEDBw5k6zgISAAAcNgsGyvI/wViypQp0qdPH7nzzjulZs2a8sILL0i+fPnklVdekexEQAIAgMOaWq0gN3+dPHlSNm7cKC1btvTuc7lc5vHatWslO9HUmg3cbrf5+GdKit1DAcLGffqk3UMAwvqz7fldHk4pIXif8Fwj87ViY2PNltEff/whp0+fllKlSvns18dbt26V7ERAkg3+/PNP8/GyimXtHgoAIIjf5YUKFQrLtWNiYqR06dJSJUTvEwUKFJCyZX2vpT0iY8aMEaciIMkGZcqUkeTkZClYsKBYkTpBPILoXwX6H6J+z+Pj4+0eDhBy/IxnL82MaDCiv8vDJS4uTpKSkkwJJVRjzvx+kzk7oooXLy65cuWS/fv3++zXxxogZScCkmyg9bhLL73U7mFEHf1FzS9r5GT8jGefcGVGMgclcXFxkp00M9OgQQNZvny5dOzY0ew7c+aMedy/f/9sHQsBCQAAUWzIkCHSq1cvadiwoVx11VUydepUOXbsmJl1k50ISAAAiGK33HKL/P777/LII4/Ivn37pF69evLxxx+f1egabgQkyHG0TqrNW1nVS4GcgJ9xhJqWZ7K7RJOZ5c6OeUwAAADnwcJoAADAdgQkAADAdgQkAADAdgQkAADjs88+M4tpHTlyxO6hIAoRkMAx9EZOumLg9ddfb/dQgKDdcccd5s190qRJPvsXL17Mis1AFghI4BgzZ86UAQMGyOrVq2XPnj12DwcImq66+fjjj8vhw4dDds1QLS0OOA0BCRwhNTVVFixYIPfdd5/JkMyePfusNPIHH3wgderUMb/kr776atmyZYv3HD2/cOHC8sknn0iNGjXMjaX+9a9/yd69e32e5+WXXzbH9RrVq1eX559/3uf48OHDpWrVqpIvXz6pVKmSjBo1StLT07PhO4CcSG/hrvcDmThx4jnPeeedd+Tyyy83a4pUqFBBnnrqKZ/jum/8+PHSs2dPs0x83759vT/vS5YskWrVqpmf1y5dusjx48fl1VdfNV9TpEgRGThwoLmTq8ecOXPMapx6Xy0dV/fu3eXAgQNh/R4AftN1SAC7zZw5092wYUPz+fvvv++uXLmy+8yZM+bxypUrda0cd40aNdyffvqpe/Pmze4bbrjBXaFCBffJkyfNObNmzXLnyZPH3bJlS/f69evdGzduNOd3797d+xyvv/66OyEhwf3OO++4d+7caT4WLVrUPXv2bO8548ePd3/55ZfupKQk93vvvecuVaqU+/HHH8/27wciX69evdw33nije+HChe64uDh3cnKy2b9o0SLz86w2bNjgdrlc7nHjxrkTExPNz3HevHnNR4/y5cu74+Pj3U8++aR7+/btZvP8vLdq1cr9zTffuFetWuUuVqyYu3Xr1u6uXbu6f/jhB/PfUUxMjHv+/Pk+/519+OGH7h07drjXrl3rbty4sbtt27be457/1g4fPpyt3ytAEZDAEa655hr31KlTzefp6enu4sWLm1+OGX9JZvzFevDgQfOLe8GCBeax/oLWc/SXtcf06dNNQOGhQc68efN8nlcDEP2lfC6TJ092N2jQIISvFNEWkKirr77afdddd50VkGjArEFFRsOGDXPXrFnTJyDp2LGjzzlZ/bzfc8897nz58rn//PNP7742bdqY/eeiwbtex/M1BCSwEyUb2C4xMVG+/vpr6datm3mcO3duc28F7SnJqHHjxt7PixYtalLVP/30k3efpq0rV67sfZyQkOBNR+uNonbs2CG9e/c25RzP9uijj5r9Hlo2uvbaa006W4+PHDlSdu/eHdbXj5xP+0i0lJLx51XpY/15y0gfb9u2zafUomWWzDL/vOt9R7RUoz+3GfdlLMls3LhR2rdvL+XKlTNlm6ZNm5r9/IzDCbiXDWyngcepU6ekTJky3n2avdOa+nPPPef3dfLkyePzWPtOPHdG0B4V9dJLL0mjRo18ztOZPZ5ZPj169JCxY8dKmzZtzO3G58+ff1ZNHwhUkyZNzM/UiBEjzOybQOXPn9+vn/es9umt5D1BuY5Bt7lz50qJEiVMIKKPaZSFExCQwFYaiLz22mvmTb9169Y+xzp27ChvvPGGaT5V69atM3/ZKZ218PPPP5sGVX/oX4oa8OzcudMEHVlZs2aNlC9fXh5++GHvvl27dgXx6oD/0em/ehdVzex56M/vl19+6XOePtbGak+gHCpbt26VgwcPmnGULVvW7NuwYUNInwMIBgEJbKWzBDS40FKKZiQy6ty5s8meTJ482TweN26cFCtWzAQXGjQUL17cBC3+0syHzjrQ59EZOGlpaeYXsj7/kCFDpEqVKuYvRs2KXHnllWZWz6JFi0L+mhGdateubYLhZ5991rvvgQceMD9rOotGy5SapdOsYObZX6GgwXxMTIxMmzZN7r33XjNLTZ8XcAp6SGArDTh0amTmYMQTkGjAsHnzZvNY/7IbNGiQNGjQQPbt2yfvv/+++QXrr7vvvttM+501a5Z5c9D6uU6frFixojneoUMHGTx4sLkFt/4lqxkTnfYLhIoG1Z4Siqpfv768+eabJgiuVauWPPLII+aciynrXIiWaPTn/a233pKaNWua/56efPLJkD8PcLEs7Wy96K8GsoGuQ9K8eXOTydC1FwAAOQ8ZEgAAYDsCEgAAYDtKNgAAwHZkSAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISIAooYttZVzZtlmzZnL//ffbsq6M3mPlyJEj5zxHjy9evNjva44ZM8YsZheMX375xTzvpk2bgroOgItDQALYHCTom6BuuursZZddZlbq1Hv8hNvChQv9XjrcnyACAILBvWwAm+l9dXQ5e723zocffij9+vUzd23VO8NmpndlDWS5/PMpWrRoSK4DAKFAhgSwWWxsrJQuXdrcafi+++4z9/Z57733fMosjz32mLlbsedOscnJydK1a1ezlL4GFjfeeKMpOXicPn3a3DBQj+sNCR988EHJvORQ5pKNBkTDhw83d4LVMWm2Ru81pNfVpftVkSJFTKbEc68VvS/LxIkTzf2A8ubNK3Xr1pW3337b53k0yNK71+pxvU7GcfpLx6XXyJcvn1SqVMncYyg9Pf2s81588UUzfj1Pvz9Hjx71Oa73MtI77MbFxZm7SIfjJnYALg4BCeAw+satmRCP5cuXS2JioixdutTcHVnfiNu0aSMFCxaUzz//3NyuvkCBAibT4vm6p556ytxI7ZVXXpEvvvhCDh06dME7F/fs2VPeeOMNczfan376yby563X1Df6dd94x5+g49u7dK88884x5rMHIa6+9Ji+88IL88MMP5uaEt912m6xatcobOHXq1Enat29vejP0BocPPfRQwN8Tfa36en788Ufz3C+99JI8/fTTPuds377d3KhOb7r48ccfy7fffiv//ve/vcfnzp1rbl6nwZ2+vgkTJpjA5tVXXw14PADCQFdqBWCPXr16uW+88Ubz+ZkzZ9xLly51x8bGuocOHeo9XqpUKXdaWpr3a+bMmeOuVq2aOd9Dj+fNm9f9ySefmMcJCQnuJ554wns8PT3dfemll3qfSzVt2tQ9aNAg83liYqKmT8zzZ2XlypXm+OHDh737Tpw44c6XL597zZo1Puf27t3b3a1bN/P5iBEj3DVr1vQ5Pnz48LOulZkeX7Ro0TmPT5482d2gQQPv49GjR7tz5crl/vXXX737PvroI7fL5XLv3bvXPK5cubJ73rx5PtcZP368u3HjxubzpKQk87zffvvtOZ8XQPjQQwLYTLMemonQzIeWQLp3725mjXjUrl3bp2/ku+++M9kAzRpkdOLECdmxY4cpU2gWo1GjRt5juXPnloYNG55VtvHQ7EWuXLmkadOmfo9bx3D8+HFp1aqVz37N0lxxxRXmc81EZByHaty4sQRqwYIFJnOjry81NdU0/cbHx/ucU65cObnkkkt8nke/n5rV0e+Vfm3v3r2lT58+3nP0OoUKFQp4PABCj4AEsJn2VcyYMcMEHdonosFDRvnz5/d5rG/IDRo0MCWIzEqUKHHRZaJA6TjUBx984BMIKO1BCZW1a9dKjx49ZOzYsaZUpQHE/PnzTVkq0LFqqSdzgKSBGAD7EZAANtOAQxtI/VW/fn2TMShZsuRZWQKPhIQE+eqrr6RJkybeTMDGjRvN12ZFszCaTdDeD22qzcyTodFmWY+aNWuawGP37t3nzKxoA6mnQddj3bp1Eog1a9aYht+HH37Yu2/Xrl1nnafj2LNnjwnqPM/jcrlMI3CpUqXM/p07d5rgBoDz0NQKRBh9Qy1evLiZWaNNrUlJSWadkIEDB8qvv/5qzhk0aJBMmjTJLC62detW09x5vjVEKlSoIL169ZK77rrLfI3nmtokqjQg0Nk1Wl76/fffTcZByyBDhw41jazaGKolkW+++UamTZvmbRS99957Zdu2bTJs2DBTOpk3b55pTg1ElSpVTLChWRF9Di3dZNWgqzNn9DVoSUu/L/r90Jk2OoNJaYZFm3D163/++Wf5/vvvzXTrKVOmBDQeAOFBQAJEGJ3Sunr1atMzoTNYNAuhvRHaQ+LJmDzwwANy++23mzdo7aXQ4OGmm24673W1bNSlSxcTvOiUWO21OHbsmDmmJRl9Q9cZMppt6N+/v9mvC6vpTBV9o9dx6EwfLeHoNGClY9QZOhrk6JRgnY2js1sC0aFDBxP06HPqaqyaMdHnzEyzTPr9aNeunbRu3Vrq1KnjM61XZ/jotF8NQjQjpFkdDY48YwVgL0s7W20eAwAAiHJkSAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgO0ISAAAgNjt/wHCgp47cNwDlQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Cell 9: Full evaluation with metrics and confusion matrix =====\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, average_precision_score\n",
    "\n",
    "model.eval()    \n",
    "y_true, y_pred, y_score = [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_values, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_score.extend(torch.softmax(logits, dim=1)[:, 1].cpu().numpy())  # Prob for class 1 (Apnea)\n",
    "\n",
    "# Classification report\n",
    "print(\"BINARY CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*40)\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "pr_auc = average_precision_score(y_true, y_score)\n",
    "print(\"\\nBINARY METRICS:\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fe881",
   "metadata": {},
   "source": [
    "# Wav trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2797e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 967.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 1388.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 1468.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 1638.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 1863.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 1938.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 2099.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 2248.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 2651.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 2745.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 2898.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 3330.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 3370.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 3423.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 3492.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[001].edf - start_sec 3574.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 3967.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 4436.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 4518.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 4722.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 4754.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 4972.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5096.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5159.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5296.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5641.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5737.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5829.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5865.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 5953.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6040.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6128.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6183.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6224.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6399.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6478.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6529.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6692.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 6912.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 7025.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 7090.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[002].edf - start_sec 7147.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 7208.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 7422.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 7649.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 7855.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 8435.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 8498.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 8620.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 8730.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 8881.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 8977.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 9766.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[003].edf - start_sec 10479.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 10827.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 10905.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 10980.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 11019.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 11171.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 11257.0 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 11346.5 beyond length 37.50s\n",
      "⚠️ Skip C:\\V89\\data2\\00000999-100507[004].edf - start_sec 11536.5 beyond length 37.50s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ch_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mMic\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSnore\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ch_name \u001b[38;5;129;01min\u001b[39;00m signal_labels:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         ch_data = f.readSignal(signal_labels.index(ch_name)).astype(np.float32)\n\u001b[32m     37\u001b[39m         channels_to_load.append(ch_data)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m channels_to_load:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchaudio\n",
    "import pyedflib\n",
    "\n",
    "# ==== CONFIG ====\n",
    "CSV_PATH = r\"C:\\V89\\Snore_Apnea_Analyze\\EDF_RML\\data_csv\\respiratory_binary_v2.csv\"\n",
    "EDF_ROOT = Path(r\"C:\\V89\\data2\")   # ที่เก็บ EDF\n",
    "OUT_WAV_ROOT = Path(r\"C:\\V89\\data3\")  # ที่จะเก็บ .wav\n",
    "TARGET_SR = 16000\n",
    "SEGMENT_DURATION = 5.0  # วินาที\n",
    "\n",
    "OUT_WAV_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# โหลด CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "wav_paths = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    edf_filename = f\"{row['patient_id']:08d}-100507[{row['segment_index']+1:03d}].edf\"\n",
    "    edf_path = EDF_ROOT / edf_filename\n",
    "\n",
    "    label = row['type']  # ใช้ชื่อคลาส หรือจะใช้ label int ก็ได้\n",
    "    start_sec = float(row['start_sec'])\n",
    "    duration = min(float(row['duration_sec']), SEGMENT_DURATION)\n",
    "\n",
    "    with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "        signal_labels = f.getSignalLabels()\n",
    "\n",
    "        channels_to_load = []\n",
    "        for ch_name in [\"Mic\", \"Snore\"]:\n",
    "            if ch_name in signal_labels:\n",
    "                ch_data = f.readSignal(signal_labels.index(ch_name)).astype(np.float32)\n",
    "                channels_to_load.append(ch_data)\n",
    "\n",
    "        if not channels_to_load:\n",
    "            print(f\"❌ No Mic or Snore found in {edf_path}\")\n",
    "            continue\n",
    "\n",
    "        # ให้ยาวเท่ากัน\n",
    "        min_len = min(len(ch) for ch in channels_to_load)\n",
    "        channels_to_load = [ch[:min_len] for ch in channels_to_load]\n",
    "\n",
    "        # รวมเป็น mono\n",
    "        waveform = np.mean(np.stack(channels_to_load, axis=0), axis=0)\n",
    "\n",
    "        # Resample ถ้าจำเป็น (ทำก่อน crop จะดีกว่าในกรณีเราจะใช้ sample index ใหม่)\n",
    "        orig_freq = f.getSampleFrequency(signal_labels.index(\"Mic\" if \"Mic\" in signal_labels else \"Snore\"))\n",
    "        waveform = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        if orig_freq != TARGET_SR:\n",
    "            waveform = torchaudio.transforms.Resample(orig_freq=orig_freq, new_freq=TARGET_SR)(waveform)\n",
    "            orig_freq = TARGET_SR\n",
    "\n",
    "        # Crop เฉพาะ segment\n",
    "        start_sample = int(start_sec * orig_freq)\n",
    "        end_sample = start_sample + int(duration * orig_freq)\n",
    "\n",
    "        # กัน start_sample เกินความยาว\n",
    "        if start_sample >= waveform.shape[1]:\n",
    "            print(f\"⚠️ Skip {edf_path} - start_sec {start_sec} beyond length {waveform.shape[1]/orig_freq:.2f}s\")\n",
    "            continue\n",
    "\n",
    "        end_sample = min(end_sample, waveform.shape[1])\n",
    "        waveform = waveform[:, start_sample:end_sample]\n",
    "\n",
    "        # Pad ถ้าสั้นกว่า target length\n",
    "        target_len = int(SEGMENT_DURATION * orig_freq)\n",
    "        if waveform.shape[1] < target_len:\n",
    "            pad_len = target_len - waveform.shape[1]\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, pad_len))\n",
    "\n",
    "        # ถ้ายังว่างอยู่ skip\n",
    "        if waveform.numel() == 0:\n",
    "            print(f\"⚠️ Empty segment in {edf_path} (index {i})\")\n",
    "            continue\n",
    "\n",
    "    # Save wav\n",
    "    out_path = OUT_WAV_ROOT / f\"{i}_{label}.wav\"\n",
    "    torchaudio.save(str(out_path), waveform, TARGET_SR)\n",
    "    wav_paths.append(str(out_path))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"[{i}/{len(df)}] Saved {out_path}\")\n",
    "\n",
    "# สร้าง CSV ใหม่ที่มี path\n",
    "df[\"wav_path\"] = wav_paths\n",
    "out_csv = CSV_PATH.replace(\".csv\", \"_with_wav.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Done! Saved new CSV with wav paths: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecbd63",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
